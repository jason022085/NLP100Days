{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 實作word2vec Skip-gram模型\n",
    "在課程中了解如何搭建CBOW模型，這次的作業目的在於透過搭建Skip-gram模型來了解另外一種word2vec的架構。\n",
    "\n",
    "Hint_1: 學員可以善用課程中以搭建好的function模組\n",
    "Hint_2: Skip_gram所需的輸入資料與目標跟CBOW有些許不同，Skip_gram是由中間字詞預測上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from utils.utility import clip_grads, convert_one_hot, preprocess, Trainer\n",
    "from utils.layers import Dense, SoftmaxWithCrossEntropy\n",
    "from utils.optimizer import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7, 1, 0, 3, 5, 4]),\n",
       " array([[6, 1],\n",
       "        [7, 0],\n",
       "        [1, 3],\n",
       "        [0, 5],\n",
       "        [3, 4],\n",
       "        [5, 2]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same corpus as in the lecture\n",
    "text = \"I am studying Natural Language Processing now.\"\n",
    "\n",
    "# define create_contexts_target function\n",
    "def create_contexts_target(corpus: List, window_size: int=1):\n",
    "\n",
    "    contexts = corpus[window_size:-window_size]\n",
    "    targets = []\n",
    "\n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size + 1):\n",
    "            if t == 0:\n",
    "                # skip target word itself\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        targets.append(cs)\n",
    "\n",
    "    return np.array(contexts), np.array(targets)\n",
    "\n",
    "# transform corpus to contexts and targets pair\n",
    "corpus, word2idx, idx2word = preprocess([text])\n",
    "contexts, targets= create_contexts_target(corpus[0], window_size=1)\n",
    "contexts, targets #context是word,targets是上下一個word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0]]),\n",
       " array([[[0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " \n",
       "        [[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0]]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform contexts and targets to one-hot encoding\n",
    "contexts = convert_one_hot(contexts, len(word2idx))\n",
    "targets = convert_one_hot(targets, len(word2idx))\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Skip-gram model\n",
    "class SkipGram:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # initialize weights\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        # create layers\n",
    "        self.in_layer = Dense(W_in)\n",
    "        self.out_layer = Dense(W_out)\n",
    "        self.loss_layers = [SoftmaxWithCrossEntropy() for i in range(window_size*2)]\n",
    "        \n",
    "\n",
    "        layers = [self.in_layer, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        # word vector matrix\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, targets):\n",
    "        h = self.in_layer.forward(contexts)\n",
    "        s = self.out_layer.forward(h)\n",
    "        \n",
    "        loss = sum([self.loss_layers[i].forward(s, targets[:, i]) for i in range(self.window_size*2)])\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        \n",
    "        ds = sum([self.loss_layers[i].backward(dout) for i in range(self.window_size*2)])\n",
    "        dh = self.out_layer.backward(ds)\n",
    "        self.in_layer.backward(dh)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                           | 48/1000 [00:00<00:02, 464.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 1/2, Loss: 4.159074027944586\n",
      "Epoch: 2, Iteration: 1/2, Loss: 4.1588080031338635\n",
      "Epoch: 3, Iteration: 1/2, Loss: 4.158909878205554\n",
      "Epoch: 4, Iteration: 1/2, Loss: 4.158926683745989\n",
      "Epoch: 5, Iteration: 1/2, Loss: 4.15880795115136\n",
      "Epoch: 6, Iteration: 1/2, Loss: 4.1587828626106464\n",
      "Epoch: 7, Iteration: 1/2, Loss: 4.158794839122095\n",
      "Epoch: 8, Iteration: 1/2, Loss: 4.158619470848961\n",
      "Epoch: 9, Iteration: 1/2, Loss: 4.158580565123341\n",
      "Epoch: 10, Iteration: 1/2, Loss: 4.158698623150226\n",
      "Epoch: 11, Iteration: 1/2, Loss: 4.158473080667029\n",
      "Epoch: 12, Iteration: 1/2, Loss: 4.158592326179356\n",
      "Epoch: 13, Iteration: 1/2, Loss: 4.158653460346009\n",
      "Epoch: 14, Iteration: 1/2, Loss: 4.1582242579414554\n",
      "Epoch: 15, Iteration: 1/2, Loss: 4.158494657713346\n",
      "Epoch: 16, Iteration: 1/2, Loss: 4.158081849773817\n",
      "Epoch: 17, Iteration: 1/2, Loss: 4.158555104165043\n",
      "Epoch: 18, Iteration: 1/2, Loss: 4.158282790855557\n",
      "Epoch: 19, Iteration: 1/2, Loss: 4.157866254687652\n",
      "Epoch: 20, Iteration: 1/2, Loss: 4.158070675926634\n",
      "Epoch: 21, Iteration: 1/2, Loss: 4.157884234369107\n",
      "Epoch: 22, Iteration: 1/2, Loss: 4.157412650863939\n",
      "Epoch: 23, Iteration: 1/2, Loss: 4.15813893555878\n",
      "Epoch: 24, Iteration: 1/2, Loss: 4.157102279314971\n",
      "Epoch: 25, Iteration: 1/2, Loss: 4.15689615973615\n",
      "Epoch: 26, Iteration: 1/2, Loss: 4.157396882257806\n",
      "Epoch: 27, Iteration: 1/2, Loss: 4.157973737362532\n",
      "Epoch: 28, Iteration: 1/2, Loss: 4.15683903553046\n",
      "Epoch: 29, Iteration: 1/2, Loss: 4.156405241818595\n",
      "Epoch: 30, Iteration: 1/2, Loss: 4.155785961304475\n",
      "Epoch: 31, Iteration: 1/2, Loss: 4.157234354278265\n",
      "Epoch: 32, Iteration: 1/2, Loss: 4.15620117033658\n",
      "Epoch: 33, Iteration: 1/2, Loss: 4.15523261973736\n",
      "Epoch: 34, Iteration: 1/2, Loss: 4.155437967437768\n",
      "Epoch: 35, Iteration: 1/2, Loss: 4.153485548488761\n",
      "Epoch: 36, Iteration: 1/2, Loss: 4.154558254277335\n",
      "Epoch: 37, Iteration: 1/2, Loss: 4.1542349464926565\n",
      "Epoch: 38, Iteration: 1/2, Loss: 4.153198298762242\n",
      "Epoch: 39, Iteration: 1/2, Loss: 4.152906494628113\n",
      "Epoch: 40, Iteration: 1/2, Loss: 4.155587144240888\n",
      "Epoch: 41, Iteration: 1/2, Loss: 4.14855891639319\n",
      "Epoch: 42, Iteration: 1/2, Loss: 4.1544844687059665\n",
      "Epoch: 43, Iteration: 1/2, Loss: 4.146942726363933\n",
      "Epoch: 44, Iteration: 1/2, Loss: 4.148921033033849\n",
      "Epoch: 45, Iteration: 1/2, Loss: 4.153348521110155\n",
      "Epoch: 46, Iteration: 1/2, Loss: 4.1438897149632306\n",
      "Epoch: 47, Iteration: 1/2, Loss: 4.143909251581363\n",
      "Epoch: 48, Iteration: 1/2, Loss: 4.144987804307659\n",
      "Epoch: 49, Iteration: 1/2, Loss: 4.148344663383973\n",
      "Epoch: 50, Iteration: 1/2, Loss: 4.144945616264033\n",
      "Epoch: 51, Iteration: 1/2, Loss: 4.130954545151256\n",
      "Epoch: 52, Iteration: 1/2, Loss: 4.146491410904325\n",
      "Epoch: 53, Iteration: 1/2, Loss: 4.1361389247384555\n",
      "Epoch: 54, Iteration: 1/2, Loss: 4.12647004547517\n",
      "Epoch: 55, Iteration: 1/2, Loss: 4.130413481633372\n",
      "Epoch: 56, Iteration: 1/2, Loss: 4.137704852159112\n",
      "Epoch: 57, Iteration: 1/2, Loss: 4.11538296325248\n",
      "Epoch: 58, Iteration: 1/2, Loss: 4.1237414938651735\n",
      "Epoch: 59, Iteration: 1/2, Loss: 4.1270843223642295\n",
      "Epoch: 60, Iteration: 1/2, Loss: 4.117250293325492\n",
      "Epoch: 61, Iteration: 1/2, Loss: 4.102401858449353\n",
      "Epoch: 62, Iteration: 1/2, Loss: 4.088134251228457\n",
      "Epoch: 63, Iteration: 1/2, Loss: 4.128298284235079\n",
      "Epoch: 64, Iteration: 1/2, Loss: 4.0841488409913635\n",
      "Epoch: 65, Iteration: 1/2, Loss: 4.091565109301432\n",
      "Epoch: 66, Iteration: 1/2, Loss: 4.072765700179032\n",
      "Epoch: 67, Iteration: 1/2, Loss: 4.0371274057064\n",
      "Epoch: 68, Iteration: 1/2, Loss: 4.055536236618827\n",
      "Epoch: 69, Iteration: 1/2, Loss: 4.048691093394513\n",
      "Epoch: 70, Iteration: 1/2, Loss: 4.095047899320017\n",
      "Epoch: 71, Iteration: 1/2, Loss: 4.011062675984963\n",
      "Epoch: 72, Iteration: 1/2, Loss: 4.033909431767071\n",
      "Epoch: 73, Iteration: 1/2, Loss: 3.991062321876756\n",
      "Epoch: 74, Iteration: 1/2, Loss: 3.9966159825172634\n",
      "Epoch: 75, Iteration: 1/2, Loss: 3.879284509530205\n",
      "Epoch: 76, Iteration: 1/2, Loss: 4.032382906073093\n",
      "Epoch: 77, Iteration: 1/2, Loss: 3.825083869186602\n",
      "Epoch: 78, Iteration: 1/2, Loss: 3.9040484766851407\n",
      "Epoch: 79, Iteration: 1/2, Loss: 3.9806835224922525\n",
      "Epoch: 80, Iteration: 1/2, Loss: 3.7764308619431906\n",
      "Epoch: 81, Iteration: 1/2, Loss: 3.911109201831362\n",
      "Epoch: 82, Iteration: 1/2, Loss: 3.7069875240436954\n",
      "Epoch: 83, Iteration: 1/2, Loss: 3.861867228094837\n",
      "Epoch: 84, Iteration: 1/2, Loss: 3.628878562177804\n",
      "Epoch: 85, Iteration: 1/2, Loss: 3.8265156855596856\n",
      "Epoch: 86, Iteration: 1/2, Loss: 3.536624962616038\n",
      "Epoch: 87, Iteration: 1/2, Loss: 3.534794742299373\n",
      "Epoch: 88, Iteration: 1/2, Loss: 3.764195196720996\n",
      "Epoch: 89, Iteration: 1/2, Loss: 3.487653903636981\n",
      "Epoch: 90, Iteration: 1/2, Loss: 3.3383183642727303\n",
      "Epoch: 91, Iteration: 1/2, Loss: 3.656854683024563\n",
      "Epoch: 92, Iteration: 1/2, Loss: 3.3114027227083978\n",
      "Epoch: 93, Iteration: 1/2, Loss: 3.414918888784376\n",
      "Epoch: 94, Iteration: 1/2, Loss: 3.134109464518576\n",
      "Epoch: 95, Iteration: 1/2, Loss: 3.250378519000135\n",
      "Epoch: 96, Iteration: 1/2, Loss: 3.055388714935237\n",
      "Epoch: 97, Iteration: 1/2, Loss: 3.276202527655905\n",
      "Epoch: 98, Iteration: 1/2, Loss: 3.0713460584203682\n",
      "Epoch: 99, Iteration: 1/2, Loss: 2.9079743813938763\n",
      "Epoch: 100, Iteration: 1/2, Loss: 3.2423085302935832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████                                                                  | 155/1000 [00:00<00:01, 462.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101, Iteration: 1/2, Loss: 2.6450662946188297\n",
      "Epoch: 102, Iteration: 1/2, Loss: 2.8710977327520046\n",
      "Epoch: 103, Iteration: 1/2, Loss: 3.072311149185632\n",
      "Epoch: 104, Iteration: 1/2, Loss: 2.6421157736792793\n",
      "Epoch: 105, Iteration: 1/2, Loss: 2.8791010365129113\n",
      "Epoch: 106, Iteration: 1/2, Loss: 2.638989701868379\n",
      "Epoch: 107, Iteration: 1/2, Loss: 2.3434157690890043\n",
      "Epoch: 108, Iteration: 1/2, Loss: 2.703232238666736\n",
      "Epoch: 109, Iteration: 1/2, Loss: 2.4418115472005826\n",
      "Epoch: 110, Iteration: 1/2, Loss: 2.531111358401378\n",
      "Epoch: 111, Iteration: 1/2, Loss: 2.7062561767547137\n",
      "Epoch: 112, Iteration: 1/2, Loss: 2.408379200022325\n",
      "Epoch: 113, Iteration: 1/2, Loss: 2.1583232312717335\n",
      "Epoch: 114, Iteration: 1/2, Loss: 2.6266902536257883\n",
      "Epoch: 115, Iteration: 1/2, Loss: 2.0034786307418666\n",
      "Epoch: 116, Iteration: 1/2, Loss: 2.5345563470949184\n",
      "Epoch: 117, Iteration: 1/2, Loss: 2.2703359998201096\n",
      "Epoch: 118, Iteration: 1/2, Loss: 2.0932001057848657\n",
      "Epoch: 119, Iteration: 1/2, Loss: 2.1600351086339282\n",
      "Epoch: 120, Iteration: 1/2, Loss: 2.1152055777305727\n",
      "Epoch: 121, Iteration: 1/2, Loss: 2.2651247219053747\n",
      "Epoch: 122, Iteration: 1/2, Loss: 2.0575475335096605\n",
      "Epoch: 123, Iteration: 1/2, Loss: 2.165339409970467\n",
      "Epoch: 124, Iteration: 1/2, Loss: 1.9301023452242443\n",
      "Epoch: 125, Iteration: 1/2, Loss: 1.9410073282078482\n",
      "Epoch: 126, Iteration: 1/2, Loss: 2.0053790161519567\n",
      "Epoch: 127, Iteration: 1/2, Loss: 2.1686318120297545\n",
      "Epoch: 128, Iteration: 1/2, Loss: 1.9090353599973784\n",
      "Epoch: 129, Iteration: 1/2, Loss: 1.934787831796689\n",
      "Epoch: 130, Iteration: 1/2, Loss: 1.941807267355372\n",
      "Epoch: 131, Iteration: 1/2, Loss: 1.8736561611151628\n",
      "Epoch: 132, Iteration: 1/2, Loss: 1.8259354846260791\n",
      "Epoch: 133, Iteration: 1/2, Loss: 1.878163115904813\n",
      "Epoch: 134, Iteration: 1/2, Loss: 1.9152340374379881\n",
      "Epoch: 135, Iteration: 1/2, Loss: 1.7489787886282753\n",
      "Epoch: 136, Iteration: 1/2, Loss: 1.8118406075196278\n",
      "Epoch: 137, Iteration: 1/2, Loss: 1.8445163566935994\n",
      "Epoch: 138, Iteration: 1/2, Loss: 1.7530563948572988\n",
      "Epoch: 139, Iteration: 1/2, Loss: 1.7680869200281188\n",
      "Epoch: 140, Iteration: 1/2, Loss: 1.7394989789778035\n",
      "Epoch: 141, Iteration: 1/2, Loss: 1.8087674244840835\n",
      "Epoch: 142, Iteration: 1/2, Loss: 1.6715938567807451\n",
      "Epoch: 143, Iteration: 1/2, Loss: 1.6986142595802267\n",
      "Epoch: 144, Iteration: 1/2, Loss: 1.7145704945731584\n",
      "Epoch: 145, Iteration: 1/2, Loss: 1.6558582869622902\n",
      "Epoch: 146, Iteration: 1/2, Loss: 1.6880841199546082\n",
      "Epoch: 147, Iteration: 1/2, Loss: 1.7240274533816704\n",
      "Epoch: 148, Iteration: 1/2, Loss: 1.670865301225552\n",
      "Epoch: 149, Iteration: 1/2, Loss: 1.6698697865640422\n",
      "Epoch: 150, Iteration: 1/2, Loss: 1.68335691083158\n",
      "Epoch: 151, Iteration: 1/2, Loss: 1.6024701067755087\n",
      "Epoch: 152, Iteration: 1/2, Loss: 1.6439149164242957\n",
      "Epoch: 153, Iteration: 1/2, Loss: 1.6040095866269275\n",
      "Epoch: 154, Iteration: 1/2, Loss: 1.6544101580778816\n",
      "Epoch: 155, Iteration: 1/2, Loss: 1.5809029647602286\n",
      "Epoch: 156, Iteration: 1/2, Loss: 1.6168637494649838\n",
      "Epoch: 157, Iteration: 1/2, Loss: 1.6136276241444143\n",
      "Epoch: 158, Iteration: 1/2, Loss: 1.5990076989832471\n",
      "Epoch: 159, Iteration: 1/2, Loss: 1.6054629469433777\n",
      "Epoch: 160, Iteration: 1/2, Loss: 1.5289556050257485\n",
      "Epoch: 161, Iteration: 1/2, Loss: 1.6166740689591084\n",
      "Epoch: 162, Iteration: 1/2, Loss: 1.5511008378996602\n",
      "Epoch: 163, Iteration: 1/2, Loss: 1.547536459414987\n",
      "Epoch: 164, Iteration: 1/2, Loss: 1.617635194657795\n",
      "Epoch: 165, Iteration: 1/2, Loss: 1.5121261993313702\n",
      "Epoch: 166, Iteration: 1/2, Loss: 1.573665342749462\n",
      "Epoch: 167, Iteration: 1/2, Loss: 1.5753816150725564\n",
      "Epoch: 168, Iteration: 1/2, Loss: 1.5037509016552155\n",
      "Epoch: 169, Iteration: 1/2, Loss: 1.5711694703693326\n",
      "Epoch: 170, Iteration: 1/2, Loss: 1.526719995358146\n",
      "Epoch: 171, Iteration: 1/2, Loss: 1.527100563744991\n",
      "Epoch: 172, Iteration: 1/2, Loss: 1.5333894676477777\n",
      "Epoch: 173, Iteration: 1/2, Loss: 1.5432354235037864\n",
      "Epoch: 174, Iteration: 1/2, Loss: 1.5327333784567778\n",
      "Epoch: 175, Iteration: 1/2, Loss: 1.5235635380208268\n",
      "Epoch: 176, Iteration: 1/2, Loss: 1.486320915491489\n",
      "Epoch: 177, Iteration: 1/2, Loss: 1.53109215064015\n",
      "Epoch: 178, Iteration: 1/2, Loss: 1.517314264343121\n",
      "Epoch: 179, Iteration: 1/2, Loss: 1.5075055334444496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████▏                                                         | 259/1000 [00:00<00:01, 488.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180, Iteration: 1/2, Loss: 1.5165034912357103\n",
      "Epoch: 181, Iteration: 1/2, Loss: 1.501296000978038\n",
      "Epoch: 182, Iteration: 1/2, Loss: 1.5030797812151824\n",
      "Epoch: 183, Iteration: 1/2, Loss: 1.5083938090110163\n",
      "Epoch: 184, Iteration: 1/2, Loss: 1.4857788278989066\n",
      "Epoch: 185, Iteration: 1/2, Loss: 1.4925758827053577\n",
      "Epoch: 186, Iteration: 1/2, Loss: 1.515532041355451\n",
      "Epoch: 187, Iteration: 1/2, Loss: 1.4807231366365134\n",
      "Epoch: 188, Iteration: 1/2, Loss: 1.4897681815454473\n",
      "Epoch: 189, Iteration: 1/2, Loss: 1.4946232330143088\n",
      "Epoch: 190, Iteration: 1/2, Loss: 1.469238540686878\n",
      "Epoch: 191, Iteration: 1/2, Loss: 1.4993769686422582\n",
      "Epoch: 192, Iteration: 1/2, Loss: 1.4845272840037596\n",
      "Epoch: 193, Iteration: 1/2, Loss: 1.485820132967456\n",
      "Epoch: 194, Iteration: 1/2, Loss: 1.4588596190684002\n",
      "Epoch: 195, Iteration: 1/2, Loss: 1.4808550579158895\n",
      "Epoch: 196, Iteration: 1/2, Loss: 1.491244153850666\n",
      "Epoch: 197, Iteration: 1/2, Loss: 1.4668817595332\n",
      "Epoch: 198, Iteration: 1/2, Loss: 1.4870524789750093\n",
      "Epoch: 199, Iteration: 1/2, Loss: 1.4607435885361668\n",
      "Epoch: 200, Iteration: 1/2, Loss: 1.4609827017518036\n",
      "Epoch: 201, Iteration: 1/2, Loss: 1.4881802773274604\n",
      "Epoch: 202, Iteration: 1/2, Loss: 1.4485727641691737\n",
      "Epoch: 203, Iteration: 1/2, Loss: 1.4659675144657072\n",
      "Epoch: 204, Iteration: 1/2, Loss: 1.4835591186338886\n",
      "Epoch: 205, Iteration: 1/2, Loss: 1.4455649481030677\n",
      "Epoch: 206, Iteration: 1/2, Loss: 1.4668835266847122\n",
      "Epoch: 207, Iteration: 1/2, Loss: 1.4669793529842154\n",
      "Epoch: 208, Iteration: 1/2, Loss: 1.4485079230465745\n",
      "Epoch: 209, Iteration: 1/2, Loss: 1.4747917012947065\n",
      "Epoch: 210, Iteration: 1/2, Loss: 1.4539479990359974\n",
      "Epoch: 211, Iteration: 1/2, Loss: 1.4538659392899813\n",
      "Epoch: 212, Iteration: 1/2, Loss: 1.453487088985539\n",
      "Epoch: 213, Iteration: 1/2, Loss: 1.4678555004404257\n",
      "Epoch: 214, Iteration: 1/2, Loss: 1.446864613587214\n",
      "Epoch: 215, Iteration: 1/2, Loss: 1.4458387384502291\n",
      "Epoch: 216, Iteration: 1/2, Loss: 1.457998107353939\n",
      "Epoch: 217, Iteration: 1/2, Loss: 1.4498327416782002\n",
      "Epoch: 218, Iteration: 1/2, Loss: 1.4523186534535384\n",
      "Epoch: 219, Iteration: 1/2, Loss: 1.4455244304117825\n",
      "Epoch: 220, Iteration: 1/2, Loss: 1.4496792504211156\n",
      "Epoch: 221, Iteration: 1/2, Loss: 1.4542071176472973\n",
      "Epoch: 222, Iteration: 1/2, Loss: 1.4378793750371166\n",
      "Epoch: 223, Iteration: 1/2, Loss: 1.4483597211242318\n",
      "Epoch: 224, Iteration: 1/2, Loss: 1.453283806957716\n",
      "Epoch: 225, Iteration: 1/2, Loss: 1.443656853389136\n",
      "Epoch: 226, Iteration: 1/2, Loss: 1.4465197323828245\n",
      "Epoch: 227, Iteration: 1/2, Loss: 1.4431950008116268\n",
      "Epoch: 228, Iteration: 1/2, Loss: 1.4350727619559773\n",
      "Epoch: 229, Iteration: 1/2, Loss: 1.4418954089881764\n",
      "Epoch: 230, Iteration: 1/2, Loss: 1.435153808854009\n",
      "Epoch: 231, Iteration: 1/2, Loss: 1.4460753206628056\n",
      "Epoch: 232, Iteration: 1/2, Loss: 1.436719302060937\n",
      "Epoch: 233, Iteration: 1/2, Loss: 1.4398825693968151\n",
      "Epoch: 234, Iteration: 1/2, Loss: 1.438714759058258\n",
      "Epoch: 235, Iteration: 1/2, Loss: 1.438752539310624\n",
      "Epoch: 236, Iteration: 1/2, Loss: 1.4425890969759347\n",
      "Epoch: 237, Iteration: 1/2, Loss: 1.4388238704681917\n",
      "Epoch: 238, Iteration: 1/2, Loss: 1.4293260763581142\n",
      "Epoch: 239, Iteration: 1/2, Loss: 1.4345674225933496\n",
      "Epoch: 240, Iteration: 1/2, Loss: 1.439892219440505\n",
      "Epoch: 241, Iteration: 1/2, Loss: 1.4304643106991177\n",
      "Epoch: 242, Iteration: 1/2, Loss: 1.4361517946081448\n",
      "Epoch: 243, Iteration: 1/2, Loss: 1.4409282629976858\n",
      "Epoch: 244, Iteration: 1/2, Loss: 1.4309541834624884\n",
      "Epoch: 245, Iteration: 1/2, Loss: 1.4274512768797325\n",
      "Epoch: 246, Iteration: 1/2, Loss: 1.4340633440835786\n",
      "Epoch: 247, Iteration: 1/2, Loss: 1.4296848075224053\n",
      "Epoch: 248, Iteration: 1/2, Loss: 1.4330270904243423\n",
      "Epoch: 249, Iteration: 1/2, Loss: 1.4249964149617511\n",
      "Epoch: 250, Iteration: 1/2, Loss: 1.4406000104008645\n",
      "Epoch: 251, Iteration: 1/2, Loss: 1.4279173437880985\n",
      "Epoch: 252, Iteration: 1/2, Loss: 1.4269291308720655\n",
      "Epoch: 253, Iteration: 1/2, Loss: 1.4246889325876224\n",
      "Epoch: 254, Iteration: 1/2, Loss: 1.4282292211348468\n",
      "Epoch: 255, Iteration: 1/2, Loss: 1.431920184066405\n",
      "Epoch: 256, Iteration: 1/2, Loss: 1.4266341493958676\n",
      "Epoch: 257, Iteration: 1/2, Loss: 1.4234792054438299\n",
      "Epoch: 258, Iteration: 1/2, Loss: 1.4333169664906653\n",
      "Epoch: 259, Iteration: 1/2, Loss: 1.427542951808495\n",
      "Epoch: 260, Iteration: 1/2, Loss: 1.422426563114025\n",
      "Epoch: 261, Iteration: 1/2, Loss: 1.425145431987967\n",
      "Epoch: 262, Iteration: 1/2, Loss: 1.4305885625719101\n",
      "Epoch: 263, Iteration: 1/2, Loss: 1.4214096583544105\n",
      "Epoch: 264, Iteration: 1/2, Loss: 1.4277022927018066\n",
      "Epoch: 265, Iteration: 1/2, Loss: 1.4192042539817662\n",
      "Epoch: 266, Iteration: 1/2, Loss: 1.4220366364646526\n",
      "Epoch: 267, Iteration: 1/2, Loss: 1.4225428313556958\n",
      "Epoch: 268, Iteration: 1/2, Loss: 1.4300464441896041\n",
      "Epoch: 269, Iteration: 1/2, Loss: 1.419226215709369\n",
      "Epoch: 270, Iteration: 1/2, Loss: 1.4260050746545292\n",
      "Epoch: 271, Iteration: 1/2, Loss: 1.4165993093118123\n",
      "Epoch: 272, Iteration: 1/2, Loss: 1.4242881110050314\n",
      "Epoch: 273, Iteration: 1/2, Loss: 1.421472007656459\n",
      "Epoch: 274, Iteration: 1/2, Loss: 1.4224489233705762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████                                                      | 308/1000 [00:00<00:01, 426.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 275, Iteration: 1/2, Loss: 1.4202031475124102\n",
      "Epoch: 276, Iteration: 1/2, Loss: 1.421705457244887\n",
      "Epoch: 277, Iteration: 1/2, Loss: 1.4169880848388545\n",
      "Epoch: 278, Iteration: 1/2, Loss: 1.4201608105013883\n",
      "Epoch: 279, Iteration: 1/2, Loss: 1.4251663895407696\n",
      "Epoch: 280, Iteration: 1/2, Loss: 1.416661448931646\n",
      "Epoch: 281, Iteration: 1/2, Loss: 1.4189923241144293\n",
      "Epoch: 282, Iteration: 1/2, Loss: 1.4181247638152974\n",
      "Epoch: 283, Iteration: 1/2, Loss: 1.41946992368702\n",
      "Epoch: 284, Iteration: 1/2, Loss: 1.4198321022798899\n",
      "Epoch: 285, Iteration: 1/2, Loss: 1.420950118307412\n",
      "Epoch: 286, Iteration: 1/2, Loss: 1.413928968563643\n",
      "Epoch: 287, Iteration: 1/2, Loss: 1.4178889929321288\n",
      "Epoch: 288, Iteration: 1/2, Loss: 1.4148808118885965\n",
      "Epoch: 289, Iteration: 1/2, Loss: 1.4205664817714323\n",
      "Epoch: 290, Iteration: 1/2, Loss: 1.4172361046915234\n",
      "Epoch: 291, Iteration: 1/2, Loss: 1.4156449686046775\n",
      "Epoch: 292, Iteration: 1/2, Loss: 1.4176883455234448\n",
      "Epoch: 293, Iteration: 1/2, Loss: 1.4162641645415097\n",
      "Epoch: 294, Iteration: 1/2, Loss: 1.413198888673957\n",
      "Epoch: 295, Iteration: 1/2, Loss: 1.4210176822219116\n",
      "Epoch: 296, Iteration: 1/2, Loss: 1.4131510574103106\n",
      "Epoch: 297, Iteration: 1/2, Loss: 1.4179030861514224\n",
      "Epoch: 298, Iteration: 1/2, Loss: 1.4151431078260925\n",
      "Epoch: 299, Iteration: 1/2, Loss: 1.412421924931885\n",
      "Epoch: 300, Iteration: 1/2, Loss: 1.4165034298096133\n",
      "Epoch: 301, Iteration: 1/2, Loss: 1.4118535867604358\n",
      "Epoch: 302, Iteration: 1/2, Loss: 1.4127331592946968\n",
      "Epoch: 303, Iteration: 1/2, Loss: 1.4141459612948957\n",
      "Epoch: 304, Iteration: 1/2, Loss: 1.416502125719683\n",
      "Epoch: 305, Iteration: 1/2, Loss: 1.412180038414697\n",
      "Epoch: 306, Iteration: 1/2, Loss: 1.414199815560247\n",
      "Epoch: 307, Iteration: 1/2, Loss: 1.4141842170301624\n",
      "Epoch: 308, Iteration: 1/2, Loss: 1.4101035197094376\n",
      "Epoch: 309, Iteration: 1/2, Loss: 1.415170029648289\n",
      "Epoch: 310, Iteration: 1/2, Loss: 1.413519780903667\n",
      "Epoch: 311, Iteration: 1/2, Loss: 1.4102491500822227\n",
      "Epoch: 312, Iteration: 1/2, Loss: 1.4124390795938144\n",
      "Epoch: 313, Iteration: 1/2, Loss: 1.4166598678949274\n",
      "Epoch: 314, Iteration: 1/2, Loss: 1.4076700456761517\n",
      "Epoch: 315, Iteration: 1/2, Loss: 1.4141485682587533\n",
      "Epoch: 316, Iteration: 1/2, Loss: 1.4117284903372425\n",
      "Epoch: 317, Iteration: 1/2, Loss: 1.41082605627553\n",
      "Epoch: 318, Iteration: 1/2, Loss: 1.4118894110884566\n",
      "Epoch: 319, Iteration: 1/2, Loss: 1.4092040569926687\n",
      "Epoch: 320, Iteration: 1/2, Loss: 1.4137656860435273\n",
      "Epoch: 321, Iteration: 1/2, Loss: 1.4096491107674014\n",
      "Epoch: 322, Iteration: 1/2, Loss: 1.4119163182724541\n",
      "Epoch: 323, Iteration: 1/2, Loss: 1.4114759997204218\n",
      "Epoch: 324, Iteration: 1/2, Loss: 1.406828870453715\n",
      "Epoch: 325, Iteration: 1/2, Loss: 1.4098111712403696\n",
      "Epoch: 326, Iteration: 1/2, Loss: 1.4120409965108944\n",
      "Epoch: 327, Iteration: 1/2, Loss: 1.4084812447203732\n",
      "Epoch: 328, Iteration: 1/2, Loss: 1.4107640032035462\n",
      "Epoch: 329, Iteration: 1/2, Loss: 1.410793872869438\n",
      "Epoch: 330, Iteration: 1/2, Loss: 1.4074097474756886\n",
      "Epoch: 331, Iteration: 1/2, Loss: 1.4109451947929903\n",
      "Epoch: 332, Iteration: 1/2, Loss: 1.409220884217195\n",
      "Epoch: 333, Iteration: 1/2, Loss: 1.4113485696981298\n",
      "Epoch: 334, Iteration: 1/2, Loss: 1.4051167207969848\n",
      "Epoch: 335, Iteration: 1/2, Loss: 1.4121574502832521\n",
      "Epoch: 336, Iteration: 1/2, Loss: 1.4086005582991945\n",
      "Epoch: 337, Iteration: 1/2, Loss: 1.4071715751021467\n",
      "Epoch: 338, Iteration: 1/2, Loss: 1.4088447164017706\n",
      "Epoch: 339, Iteration: 1/2, Loss: 1.4095514241598037\n",
      "Epoch: 340, Iteration: 1/2, Loss: 1.4068072575850992\n",
      "Epoch: 341, Iteration: 1/2, Loss: 1.4066022086027303\n",
      "Epoch: 342, Iteration: 1/2, Loss: 1.4084229567392608\n",
      "Epoch: 343, Iteration: 1/2, Loss: 1.4094033775514623\n",
      "Epoch: 344, Iteration: 1/2, Loss: 1.4041343638747499\n",
      "Epoch: 345, Iteration: 1/2, Loss: 1.4091417169098595\n",
      "Epoch: 346, Iteration: 1/2, Loss: 1.4061637754874434\n",
      "Epoch: 347, Iteration: 1/2, Loss: 1.4106568551814012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████████▏                                             | 413/1000 [00:00<00:01, 458.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 348, Iteration: 1/2, Loss: 1.405517138330199\n",
      "Epoch: 349, Iteration: 1/2, Loss: 1.4069349312564072\n",
      "Epoch: 350, Iteration: 1/2, Loss: 1.4052016792268998\n",
      "Epoch: 351, Iteration: 1/2, Loss: 1.4097522834688196\n",
      "Epoch: 352, Iteration: 1/2, Loss: 1.4069793471832788\n",
      "Epoch: 353, Iteration: 1/2, Loss: 1.4048204152878077\n",
      "Epoch: 354, Iteration: 1/2, Loss: 1.4081324298756954\n",
      "Epoch: 355, Iteration: 1/2, Loss: 1.4059887702684204\n",
      "Epoch: 356, Iteration: 1/2, Loss: 1.4029432166264568\n",
      "Epoch: 357, Iteration: 1/2, Loss: 1.4077733801967334\n",
      "Epoch: 358, Iteration: 1/2, Loss: 1.4063651027799602\n",
      "Epoch: 359, Iteration: 1/2, Loss: 1.404160163515344\n",
      "Epoch: 360, Iteration: 1/2, Loss: 1.40548306387285\n",
      "Epoch: 361, Iteration: 1/2, Loss: 1.4091256610501701\n",
      "Epoch: 362, Iteration: 1/2, Loss: 1.4035794539197939\n",
      "Epoch: 363, Iteration: 1/2, Loss: 1.4040224404649813\n",
      "Epoch: 364, Iteration: 1/2, Loss: 1.4071638921320104\n",
      "Epoch: 365, Iteration: 1/2, Loss: 1.404987203360152\n",
      "Epoch: 366, Iteration: 1/2, Loss: 1.4054253216513983\n",
      "Epoch: 367, Iteration: 1/2, Loss: 1.4052043624108275\n",
      "Epoch: 368, Iteration: 1/2, Loss: 1.4045463753514824\n",
      "Epoch: 369, Iteration: 1/2, Loss: 1.4048627004198924\n",
      "Epoch: 370, Iteration: 1/2, Loss: 1.4065318438915118\n",
      "Epoch: 371, Iteration: 1/2, Loss: 1.4043274121823783\n",
      "Epoch: 372, Iteration: 1/2, Loss: 1.4031554626700604\n",
      "Epoch: 373, Iteration: 1/2, Loss: 1.4047991610568782\n",
      "Epoch: 374, Iteration: 1/2, Loss: 1.4044469327928568\n",
      "Epoch: 375, Iteration: 1/2, Loss: 1.4027340448534598\n",
      "Epoch: 376, Iteration: 1/2, Loss: 1.4056926628142712\n",
      "Epoch: 377, Iteration: 1/2, Loss: 1.4037215298081156\n",
      "Epoch: 378, Iteration: 1/2, Loss: 1.4041551326774395\n",
      "Epoch: 379, Iteration: 1/2, Loss: 1.4024769033117894\n",
      "Epoch: 380, Iteration: 1/2, Loss: 1.4054709790791102\n",
      "Epoch: 381, Iteration: 1/2, Loss: 1.4038901736671192\n",
      "Epoch: 382, Iteration: 1/2, Loss: 1.403605123889008\n",
      "Epoch: 383, Iteration: 1/2, Loss: 1.403643142058443\n",
      "Epoch: 384, Iteration: 1/2, Loss: 1.4031277832770908\n",
      "Epoch: 385, Iteration: 1/2, Loss: 1.4031266211087696\n",
      "Epoch: 386, Iteration: 1/2, Loss: 1.4042076147826195\n",
      "Epoch: 387, Iteration: 1/2, Loss: 1.4039541495008878\n",
      "Epoch: 388, Iteration: 1/2, Loss: 1.4022577240164396\n",
      "Epoch: 389, Iteration: 1/2, Loss: 1.402697389518289\n",
      "Epoch: 390, Iteration: 1/2, Loss: 1.4045968009711127\n",
      "Epoch: 391, Iteration: 1/2, Loss: 1.4012791884427394\n",
      "Epoch: 392, Iteration: 1/2, Loss: 1.4032387138255453\n",
      "Epoch: 393, Iteration: 1/2, Loss: 1.4029766401272292\n",
      "Epoch: 394, Iteration: 1/2, Loss: 1.4020383756605468\n",
      "Epoch: 395, Iteration: 1/2, Loss: 1.4026106953801436\n",
      "Epoch: 396, Iteration: 1/2, Loss: 1.4041213020599725\n",
      "Epoch: 397, Iteration: 1/2, Loss: 1.4024519282149055\n",
      "Epoch: 398, Iteration: 1/2, Loss: 1.4022100126485633\n",
      "Epoch: 399, Iteration: 1/2, Loss: 1.3997605595966598\n",
      "Epoch: 400, Iteration: 1/2, Loss: 1.4032192987644474\n",
      "Epoch: 401, Iteration: 1/2, Loss: 1.4012272293196188\n",
      "Epoch: 402, Iteration: 1/2, Loss: 1.4034915367623984\n",
      "Epoch: 403, Iteration: 1/2, Loss: 1.4021519577268706\n",
      "Epoch: 404, Iteration: 1/2, Loss: 1.4013445728474636\n",
      "Epoch: 405, Iteration: 1/2, Loss: 1.4026139883063793\n",
      "Epoch: 406, Iteration: 1/2, Loss: 1.401205510387491\n",
      "Epoch: 407, Iteration: 1/2, Loss: 1.401830393736911\n",
      "Epoch: 408, Iteration: 1/2, Loss: 1.4030486825621549\n",
      "Epoch: 409, Iteration: 1/2, Loss: 1.400214972588413\n",
      "Epoch: 410, Iteration: 1/2, Loss: 1.4015733727472561\n",
      "Epoch: 411, Iteration: 1/2, Loss: 1.4028164196679207\n",
      "Epoch: 412, Iteration: 1/2, Loss: 1.4002229197404792\n",
      "Epoch: 413, Iteration: 1/2, Loss: 1.4024348244511438\n",
      "Epoch: 414, Iteration: 1/2, Loss: 1.399820478812358\n",
      "Epoch: 415, Iteration: 1/2, Loss: 1.4014729505129289\n",
      "Epoch: 416, Iteration: 1/2, Loss: 1.4013998480450307\n",
      "Epoch: 417, Iteration: 1/2, Loss: 1.4007858424702153\n",
      "Epoch: 418, Iteration: 1/2, Loss: 1.4008250541827\n",
      "Epoch: 419, Iteration: 1/2, Loss: 1.4022321534395297\n",
      "Epoch: 420, Iteration: 1/2, Loss: 1.3998519437657437\n",
      "Epoch: 421, Iteration: 1/2, Loss: 1.4009720128697365\n",
      "Epoch: 422, Iteration: 1/2, Loss: 1.3993715593951332\n",
      "Epoch: 423, Iteration: 1/2, Loss: 1.4016813478655825\n",
      "Epoch: 424, Iteration: 1/2, Loss: 1.4004754609675274\n",
      "Epoch: 425, Iteration: 1/2, Loss: 1.4006164774157286\n",
      "Epoch: 426, Iteration: 1/2, Loss: 1.400346148632117\n",
      "Epoch: 427, Iteration: 1/2, Loss: 1.401779984843449\n",
      "Epoch: 428, Iteration: 1/2, Loss: 1.3991593773642022\n",
      "Epoch: 429, Iteration: 1/2, Loss: 1.3994116670728673\n",
      "Epoch: 430, Iteration: 1/2, Loss: 1.4003776536456067\n",
      "Epoch: 431, Iteration: 1/2, Loss: 1.4023308372899166\n",
      "Epoch: 432, Iteration: 1/2, Loss: 1.3992497646266213\n",
      "Epoch: 433, Iteration: 1/2, Loss: 1.4010449112952639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████                                     | 526/1000 [00:01<00:00, 493.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 434, Iteration: 1/2, Loss: 1.39879693825306\n",
      "Epoch: 435, Iteration: 1/2, Loss: 1.4003730190604533\n",
      "Epoch: 436, Iteration: 1/2, Loss: 1.3986492712019838\n",
      "Epoch: 437, Iteration: 1/2, Loss: 1.4019861675640632\n",
      "Epoch: 438, Iteration: 1/2, Loss: 1.3998146589382878\n",
      "Epoch: 439, Iteration: 1/2, Loss: 1.3985945213521767\n",
      "Epoch: 440, Iteration: 1/2, Loss: 1.3996209830345605\n",
      "Epoch: 441, Iteration: 1/2, Loss: 1.3999321884206155\n",
      "Epoch: 442, Iteration: 1/2, Loss: 1.4003204586291247\n",
      "Epoch: 443, Iteration: 1/2, Loss: 1.3988314055267907\n",
      "Epoch: 444, Iteration: 1/2, Loss: 1.39840513495621\n",
      "Epoch: 445, Iteration: 1/2, Loss: 1.3995543025857877\n",
      "Epoch: 446, Iteration: 1/2, Loss: 1.400105959170201\n",
      "Epoch: 447, Iteration: 1/2, Loss: 1.3992845397065166\n",
      "Epoch: 448, Iteration: 1/2, Loss: 1.3996697357371501\n",
      "Epoch: 449, Iteration: 1/2, Loss: 1.3992398416625962\n",
      "Epoch: 450, Iteration: 1/2, Loss: 1.397941705432189\n",
      "Epoch: 451, Iteration: 1/2, Loss: 1.4000108930859687\n",
      "Epoch: 452, Iteration: 1/2, Loss: 1.39930261614836\n",
      "Epoch: 453, Iteration: 1/2, Loss: 1.3982027476997083\n",
      "Epoch: 454, Iteration: 1/2, Loss: 1.4000595484063232\n",
      "Epoch: 455, Iteration: 1/2, Loss: 1.3977138089325147\n",
      "Epoch: 456, Iteration: 1/2, Loss: 1.3996233282070785\n",
      "Epoch: 457, Iteration: 1/2, Loss: 1.3988469270998407\n",
      "Epoch: 458, Iteration: 1/2, Loss: 1.400063676921228\n",
      "Epoch: 459, Iteration: 1/2, Loss: 1.3986899218421216\n",
      "Epoch: 460, Iteration: 1/2, Loss: 1.3977096932935575\n",
      "Epoch: 461, Iteration: 1/2, Loss: 1.3979169953939197\n",
      "Epoch: 462, Iteration: 1/2, Loss: 1.3993223245959614\n",
      "Epoch: 463, Iteration: 1/2, Loss: 1.3987649633195218\n",
      "Epoch: 464, Iteration: 1/2, Loss: 1.39816409996999\n",
      "Epoch: 465, Iteration: 1/2, Loss: 1.3994777661440476\n",
      "Epoch: 466, Iteration: 1/2, Loss: 1.3974316648745673\n",
      "Epoch: 467, Iteration: 1/2, Loss: 1.399483062072723\n",
      "Epoch: 468, Iteration: 1/2, Loss: 1.3982343644618629\n",
      "Epoch: 469, Iteration: 1/2, Loss: 1.3975772547338243\n",
      "Epoch: 470, Iteration: 1/2, Loss: 1.3980398444653597\n",
      "Epoch: 471, Iteration: 1/2, Loss: 1.3985004474062848\n",
      "Epoch: 472, Iteration: 1/2, Loss: 1.3981203857906055\n",
      "Epoch: 473, Iteration: 1/2, Loss: 1.3978800220158196\n",
      "Epoch: 474, Iteration: 1/2, Loss: 1.3981858586449971\n",
      "Epoch: 475, Iteration: 1/2, Loss: 1.3981162705151169\n",
      "Epoch: 476, Iteration: 1/2, Loss: 1.3979960099430055\n",
      "Epoch: 477, Iteration: 1/2, Loss: 1.3979540053548267\n",
      "Epoch: 478, Iteration: 1/2, Loss: 1.3986335705725808\n",
      "Epoch: 479, Iteration: 1/2, Loss: 1.3973573752325803\n",
      "Epoch: 480, Iteration: 1/2, Loss: 1.3976517952615308\n",
      "Epoch: 481, Iteration: 1/2, Loss: 1.3978641192965986\n",
      "Epoch: 482, Iteration: 1/2, Loss: 1.3983540659241998\n",
      "Epoch: 483, Iteration: 1/2, Loss: 1.396283613099865\n",
      "Epoch: 484, Iteration: 1/2, Loss: 1.3975330853145236\n",
      "Epoch: 485, Iteration: 1/2, Loss: 1.399184489550442\n",
      "Epoch: 486, Iteration: 1/2, Loss: 1.396884772700222\n",
      "Epoch: 487, Iteration: 1/2, Loss: 1.3974465320857214\n",
      "Epoch: 488, Iteration: 1/2, Loss: 1.3976152334688383\n",
      "Epoch: 489, Iteration: 1/2, Loss: 1.3974390540769484\n",
      "Epoch: 490, Iteration: 1/2, Loss: 1.3975289386335377\n",
      "Epoch: 491, Iteration: 1/2, Loss: 1.397140202793195\n",
      "Epoch: 492, Iteration: 1/2, Loss: 1.3977165112146952\n",
      "Epoch: 493, Iteration: 1/2, Loss: 1.39705335779528\n",
      "Epoch: 494, Iteration: 1/2, Loss: 1.398061794658274\n",
      "Epoch: 495, Iteration: 1/2, Loss: 1.3965711866647719\n",
      "Epoch: 496, Iteration: 1/2, Loss: 1.3972088595014307\n",
      "Epoch: 497, Iteration: 1/2, Loss: 1.3963901289967684\n",
      "Epoch: 498, Iteration: 1/2, Loss: 1.397968486976723\n",
      "Epoch: 499, Iteration: 1/2, Loss: 1.3978990329219847\n",
      "Epoch: 500, Iteration: 1/2, Loss: 1.3962343125830678\n",
      "Epoch: 501, Iteration: 1/2, Loss: 1.3978478606966416\n",
      "Epoch: 502, Iteration: 1/2, Loss: 1.3961099988719865\n",
      "Epoch: 503, Iteration: 1/2, Loss: 1.396225042548041\n",
      "Epoch: 504, Iteration: 1/2, Loss: 1.3976702652415465\n",
      "Epoch: 505, Iteration: 1/2, Loss: 1.3976469563468252\n",
      "Epoch: 506, Iteration: 1/2, Loss: 1.396124260419557\n",
      "Epoch: 507, Iteration: 1/2, Loss: 1.396038089463837\n",
      "Epoch: 508, Iteration: 1/2, Loss: 1.3977042281875782\n",
      "Epoch: 509, Iteration: 1/2, Loss: 1.3957451550636373\n",
      "Epoch: 510, Iteration: 1/2, Loss: 1.3967796489883963\n",
      "Epoch: 511, Iteration: 1/2, Loss: 1.3974471982752392\n",
      "Epoch: 512, Iteration: 1/2, Loss: 1.3964766098186578\n",
      "Epoch: 513, Iteration: 1/2, Loss: 1.3967394125150008\n",
      "Epoch: 514, Iteration: 1/2, Loss: 1.3965147916844645\n",
      "Epoch: 515, Iteration: 1/2, Loss: 1.3967234344018626\n",
      "Epoch: 516, Iteration: 1/2, Loss: 1.397043110544729\n",
      "Epoch: 517, Iteration: 1/2, Loss: 1.395692385423287\n",
      "Epoch: 518, Iteration: 1/2, Loss: 1.3958141017629604\n",
      "Epoch: 519, Iteration: 1/2, Loss: 1.3979395623829123\n",
      "Epoch: 520, Iteration: 1/2, Loss: 1.3955664828327181\n",
      "Epoch: 521, Iteration: 1/2, Loss: 1.3964620464340705\n",
      "Epoch: 522, Iteration: 1/2, Loss: 1.395573521145757\n",
      "Epoch: 523, Iteration: 1/2, Loss: 1.3969824652948768\n",
      "Epoch: 524, Iteration: 1/2, Loss: 1.3962977533572187\n",
      "Epoch: 525, Iteration: 1/2, Loss: 1.3963650414713094\n",
      "Epoch: 526, Iteration: 1/2, Loss: 1.3959869292334535\n",
      "Epoch: 527, Iteration: 1/2, Loss: 1.3963602880311572\n",
      "Epoch: 528, Iteration: 1/2, Loss: 1.3961314417780724\n",
      "Epoch: 529, Iteration: 1/2, Loss: 1.3961054362561471\n",
      "Epoch: 530, Iteration: 1/2, Loss: 1.3952234671534747\n",
      "Epoch: 531, Iteration: 1/2, Loss: 1.3974270653791865\n",
      "Epoch: 532, Iteration: 1/2, Loss: 1.395363510895799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████████▉                                 | 576/1000 [00:01<00:00, 491.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 533, Iteration: 1/2, Loss: 1.3959819229707722\n",
      "Epoch: 534, Iteration: 1/2, Loss: 1.3953252660888125\n",
      "Epoch: 535, Iteration: 1/2, Loss: 1.3965249444384824\n",
      "Epoch: 536, Iteration: 1/2, Loss: 1.3958276144722337\n",
      "Epoch: 537, Iteration: 1/2, Loss: 1.3953338986075963\n",
      "Epoch: 538, Iteration: 1/2, Loss: 1.3957356857852146\n",
      "Epoch: 539, Iteration: 1/2, Loss: 1.397217844463887\n",
      "Epoch: 540, Iteration: 1/2, Loss: 1.3948957262549797\n",
      "Epoch: 541, Iteration: 1/2, Loss: 1.396034785919152\n",
      "Epoch: 542, Iteration: 1/2, Loss: 1.3948458143920073\n",
      "Epoch: 543, Iteration: 1/2, Loss: 1.3957583717953255\n",
      "Epoch: 544, Iteration: 1/2, Loss: 1.3961867237196586\n",
      "Epoch: 545, Iteration: 1/2, Loss: 1.3958173340203317\n",
      "Epoch: 546, Iteration: 1/2, Loss: 1.395591364509428\n",
      "Epoch: 547, Iteration: 1/2, Loss: 1.3955156414533831\n",
      "Epoch: 548, Iteration: 1/2, Loss: 1.3956159140568671\n",
      "Epoch: 549, Iteration: 1/2, Loss: 1.3955815295815746\n",
      "Epoch: 550, Iteration: 1/2, Loss: 1.3953819606849975\n",
      "Epoch: 551, Iteration: 1/2, Loss: 1.3954872910897005\n",
      "Epoch: 552, Iteration: 1/2, Loss: 1.3955098066857885\n",
      "Epoch: 553, Iteration: 1/2, Loss: 1.394742423898593\n",
      "Epoch: 554, Iteration: 1/2, Loss: 1.3961625784459533\n",
      "Epoch: 555, Iteration: 1/2, Loss: 1.395204764509761\n",
      "Epoch: 556, Iteration: 1/2, Loss: 1.3953914265693919\n",
      "Epoch: 557, Iteration: 1/2, Loss: 1.3952674629119461\n",
      "Epoch: 558, Iteration: 1/2, Loss: 1.3958397838826833\n",
      "Epoch: 559, Iteration: 1/2, Loss: 1.3947472368766456\n",
      "Epoch: 560, Iteration: 1/2, Loss: 1.3957467915339419\n",
      "Epoch: 561, Iteration: 1/2, Loss: 1.394152560052278\n",
      "Epoch: 562, Iteration: 1/2, Loss: 1.3955763761935431\n",
      "Epoch: 563, Iteration: 1/2, Loss: 1.395819781366916\n",
      "Epoch: 564, Iteration: 1/2, Loss: 1.394573152561064\n",
      "Epoch: 565, Iteration: 1/2, Loss: 1.3951283862250254\n",
      "Epoch: 566, Iteration: 1/2, Loss: 1.3957201668481765\n",
      "Epoch: 567, Iteration: 1/2, Loss: 1.3945113725563623\n",
      "Epoch: 568, Iteration: 1/2, Loss: 1.3955661223180233\n",
      "Epoch: 569, Iteration: 1/2, Loss: 1.3944770830251225\n",
      "Epoch: 570, Iteration: 1/2, Loss: 1.3944026649395538\n",
      "Epoch: 571, Iteration: 1/2, Loss: 1.3955427475216826\n",
      "Epoch: 572, Iteration: 1/2, Loss: 1.395525755218539\n",
      "Epoch: 573, Iteration: 1/2, Loss: 1.3941343175908012\n",
      "Epoch: 574, Iteration: 1/2, Loss: 1.3944180395732786\n",
      "Epoch: 575, Iteration: 1/2, Loss: 1.3960427543910727\n",
      "Epoch: 576, Iteration: 1/2, Loss: 1.394840232777329\n",
      "Epoch: 577, Iteration: 1/2, Loss: 1.3942636494014695\n",
      "Epoch: 578, Iteration: 1/2, Loss: 1.394796824853148\n",
      "Epoch: 579, Iteration: 1/2, Loss: 1.3948696477957196\n",
      "Epoch: 580, Iteration: 1/2, Loss: 1.3951113569388593\n",
      "Epoch: 581, Iteration: 1/2, Loss: 1.393589911577848\n",
      "Epoch: 582, Iteration: 1/2, Loss: 1.3947690949679694\n",
      "Epoch: 583, Iteration: 1/2, Loss: 1.3952681889462846\n",
      "Epoch: 584, Iteration: 1/2, Loss: 1.3952749170251302\n",
      "Epoch: 585, Iteration: 1/2, Loss: 1.393432474440437\n",
      "Epoch: 586, Iteration: 1/2, Loss: 1.3945483922844573\n",
      "Epoch: 587, Iteration: 1/2, Loss: 1.3945908216115035\n",
      "Epoch: 588, Iteration: 1/2, Loss: 1.3946333312503958\n",
      "Epoch: 589, Iteration: 1/2, Loss: 1.3951389690146372\n",
      "Epoch: 590, Iteration: 1/2, Loss: 1.3950645981712395\n",
      "Epoch: 591, Iteration: 1/2, Loss: 1.3940337185950078\n",
      "Epoch: 592, Iteration: 1/2, Loss: 1.3938922069865867\n",
      "Epoch: 593, Iteration: 1/2, Loss: 1.394870582286877\n",
      "Epoch: 594, Iteration: 1/2, Loss: 1.3950462237014711\n",
      "Epoch: 595, Iteration: 1/2, Loss: 1.394412269150322\n",
      "Epoch: 596, Iteration: 1/2, Loss: 1.3937181715883347\n",
      "Epoch: 597, Iteration: 1/2, Loss: 1.394965120379013\n",
      "Epoch: 598, Iteration: 1/2, Loss: 1.3938468737046574\n",
      "Epoch: 599, Iteration: 1/2, Loss: 1.3943763384980097\n",
      "Epoch: 600, Iteration: 1/2, Loss: 1.3943228455212806\n",
      "Epoch: 601, Iteration: 1/2, Loss: 1.3948588035921397\n",
      "Epoch: 602, Iteration: 1/2, Loss: 1.3941992540149108\n",
      "Epoch: 603, Iteration: 1/2, Loss: 1.3935856529076625\n",
      "Epoch: 604, Iteration: 1/2, Loss: 1.3949440618185573\n",
      "Epoch: 605, Iteration: 1/2, Loss: 1.3937313549756212\n",
      "Epoch: 606, Iteration: 1/2, Loss: 1.393508276795019\n",
      "Epoch: 607, Iteration: 1/2, Loss: 1.3946129666442855\n",
      "Epoch: 608, Iteration: 1/2, Loss: 1.394213761108239\n",
      "Epoch: 609, Iteration: 1/2, Loss: 1.3936051856569183\n",
      "Epoch: 610, Iteration: 1/2, Loss: 1.3946120334782788\n",
      "Epoch: 611, Iteration: 1/2, Loss: 1.394638039336831\n",
      "Epoch: 612, Iteration: 1/2, Loss: 1.3929618196725886\n",
      "Epoch: 613, Iteration: 1/2, Loss: 1.3946517495825737\n",
      "Epoch: 614, Iteration: 1/2, Loss: 1.3939389266481106\n",
      "Epoch: 615, Iteration: 1/2, Loss: 1.3940030544699482\n",
      "Epoch: 616, Iteration: 1/2, Loss: 1.3946151557683566\n",
      "Epoch: 617, Iteration: 1/2, Loss: 1.3934854138861192\n",
      "Epoch: 618, Iteration: 1/2, Loss: 1.3933411580149997\n",
      "Epoch: 619, Iteration: 1/2, Loss: 1.3943391914090817\n",
      "Epoch: 620, Iteration: 1/2, Loss: 1.3939448929679137\n",
      "Epoch: 621, Iteration: 1/2, Loss: 1.3939053319530483\n",
      "Epoch: 622, Iteration: 1/2, Loss: 1.3939326134401144\n",
      "Epoch: 623, Iteration: 1/2, Loss: 1.3943238862027354\n",
      "Epoch: 624, Iteration: 1/2, Loss: 1.3933207023952816\n",
      "Epoch: 625, Iteration: 1/2, Loss: 1.3932640924771351\n",
      "Epoch: 626, Iteration: 1/2, Loss: 1.394912394853093\n",
      "Epoch: 627, Iteration: 1/2, Loss: 1.3932554220560047\n",
      "Epoch: 628, Iteration: 1/2, Loss: 1.39423756414025\n",
      "Epoch: 629, Iteration: 1/2, Loss: 1.3932087158655189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████████████████████████████▎                        | 684/1000 [00:01<00:00, 493.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 630, Iteration: 1/2, Loss: 1.393821415993067\n",
      "Epoch: 631, Iteration: 1/2, Loss: 1.393665153153311\n",
      "Epoch: 632, Iteration: 1/2, Loss: 1.3935759447006584\n",
      "Epoch: 633, Iteration: 1/2, Loss: 1.3937576385074946\n",
      "Epoch: 634, Iteration: 1/2, Loss: 1.3935848610684252\n",
      "Epoch: 635, Iteration: 1/2, Loss: 1.3932374711374038\n",
      "Epoch: 636, Iteration: 1/2, Loss: 1.393914413868405\n",
      "Epoch: 637, Iteration: 1/2, Loss: 1.3937971274658714\n",
      "Epoch: 638, Iteration: 1/2, Loss: 1.3934998585645375\n",
      "Epoch: 639, Iteration: 1/2, Loss: 1.393588528887892\n",
      "Epoch: 640, Iteration: 1/2, Loss: 1.3933876093052717\n",
      "Epoch: 641, Iteration: 1/2, Loss: 1.3937244208944182\n",
      "Epoch: 642, Iteration: 1/2, Loss: 1.393431501406086\n",
      "Epoch: 643, Iteration: 1/2, Loss: 1.3939787061951594\n",
      "Epoch: 644, Iteration: 1/2, Loss: 1.3934421808357067\n",
      "Epoch: 645, Iteration: 1/2, Loss: 1.3929982306413045\n",
      "Epoch: 646, Iteration: 1/2, Loss: 1.3933780593834442\n",
      "Epoch: 647, Iteration: 1/2, Loss: 1.3934316226906978\n",
      "Epoch: 648, Iteration: 1/2, Loss: 1.3939698055395113\n",
      "Epoch: 649, Iteration: 1/2, Loss: 1.392371913716668\n",
      "Epoch: 650, Iteration: 1/2, Loss: 1.393403500213466\n",
      "Epoch: 651, Iteration: 1/2, Loss: 1.3933255954363681\n",
      "Epoch: 652, Iteration: 1/2, Loss: 1.3938491547028713\n",
      "Epoch: 653, Iteration: 1/2, Loss: 1.3933405534424619\n",
      "Epoch: 654, Iteration: 1/2, Loss: 1.3931528674768212\n",
      "Epoch: 655, Iteration: 1/2, Loss: 1.3934096362112067\n",
      "Epoch: 656, Iteration: 1/2, Loss: 1.3931522358807655\n",
      "Epoch: 657, Iteration: 1/2, Loss: 1.3938487073771582\n",
      "Epoch: 658, Iteration: 1/2, Loss: 1.3927801081950462\n",
      "Epoch: 659, Iteration: 1/2, Loss: 1.3937127418192634\n",
      "Epoch: 660, Iteration: 1/2, Loss: 1.3927074359217193\n",
      "Epoch: 661, Iteration: 1/2, Loss: 1.3936602590107618\n",
      "Epoch: 662, Iteration: 1/2, Loss: 1.3927081559576568\n",
      "Epoch: 663, Iteration: 1/2, Loss: 1.3931428470995102\n",
      "Epoch: 664, Iteration: 1/2, Loss: 1.392712728257019\n",
      "Epoch: 665, Iteration: 1/2, Loss: 1.3935784721571933\n",
      "Epoch: 666, Iteration: 1/2, Loss: 1.3931808939147183\n",
      "Epoch: 667, Iteration: 1/2, Loss: 1.393062614539355\n",
      "Epoch: 668, Iteration: 1/2, Loss: 1.3934209416852212\n",
      "Epoch: 669, Iteration: 1/2, Loss: 1.3926670222809472\n",
      "Epoch: 670, Iteration: 1/2, Loss: 1.393080336091819\n",
      "Epoch: 671, Iteration: 1/2, Loss: 1.3930362864208294\n",
      "Epoch: 672, Iteration: 1/2, Loss: 1.3925820868736238\n",
      "Epoch: 673, Iteration: 1/2, Loss: 1.393329235207443\n",
      "Epoch: 674, Iteration: 1/2, Loss: 1.3926084841435864\n",
      "Epoch: 675, Iteration: 1/2, Loss: 1.3934572113225507\n",
      "Epoch: 676, Iteration: 1/2, Loss: 1.3930143621590243\n",
      "Epoch: 677, Iteration: 1/2, Loss: 1.3928272133128956\n",
      "Epoch: 678, Iteration: 1/2, Loss: 1.393044746433547\n",
      "Epoch: 679, Iteration: 1/2, Loss: 1.3928930041153589\n",
      "Epoch: 680, Iteration: 1/2, Loss: 1.3928904447864516\n",
      "Epoch: 681, Iteration: 1/2, Loss: 1.3932464717725614\n",
      "Epoch: 682, Iteration: 1/2, Loss: 1.3921389043294115\n",
      "Epoch: 683, Iteration: 1/2, Loss: 1.3932056819098633\n",
      "Epoch: 684, Iteration: 1/2, Loss: 1.3932264819832927\n",
      "Epoch: 685, Iteration: 1/2, Loss: 1.3929407312505364\n",
      "Epoch: 686, Iteration: 1/2, Loss: 1.3923823438651708\n",
      "Epoch: 687, Iteration: 1/2, Loss: 1.392773774499911\n",
      "Epoch: 688, Iteration: 1/2, Loss: 1.3931792028934873\n",
      "Epoch: 689, Iteration: 1/2, Loss: 1.39194995193174\n",
      "Epoch: 690, Iteration: 1/2, Loss: 1.393637876504474\n",
      "Epoch: 691, Iteration: 1/2, Loss: 1.3918296554125678\n",
      "Epoch: 692, Iteration: 1/2, Loss: 1.393276796945783\n",
      "Epoch: 693, Iteration: 1/2, Loss: 1.3929673077414493\n",
      "Epoch: 694, Iteration: 1/2, Loss: 1.3923030378286687\n",
      "Epoch: 695, Iteration: 1/2, Loss: 1.3922662085895754\n",
      "Epoch: 696, Iteration: 1/2, Loss: 1.3935401003330938\n",
      "Epoch: 697, Iteration: 1/2, Loss: 1.391905482551128\n",
      "Epoch: 698, Iteration: 1/2, Loss: 1.393016106015395\n",
      "Epoch: 699, Iteration: 1/2, Loss: 1.3930750897624398\n",
      "Epoch: 700, Iteration: 1/2, Loss: 1.3918100489625522\n",
      "Epoch: 701, Iteration: 1/2, Loss: 1.3928900678834835\n",
      "Epoch: 702, Iteration: 1/2, Loss: 1.3930524466267937\n",
      "Epoch: 703, Iteration: 1/2, Loss: 1.3926379427273967\n",
      "Epoch: 704, Iteration: 1/2, Loss: 1.39215372592981\n",
      "Epoch: 705, Iteration: 1/2, Loss: 1.3925250821373836\n",
      "Epoch: 706, Iteration: 1/2, Loss: 1.3929138094311035\n",
      "Epoch: 707, Iteration: 1/2, Loss: 1.3925846105541042\n",
      "Epoch: 708, Iteration: 1/2, Loss: 1.39212517931036\n",
      "Epoch: 709, Iteration: 1/2, Loss: 1.392883321325924\n",
      "Epoch: 710, Iteration: 1/2, Loss: 1.3923786504207643\n",
      "Epoch: 711, Iteration: 1/2, Loss: 1.392069850231414\n",
      "Epoch: 712, Iteration: 1/2, Loss: 1.3920992507218901\n",
      "Epoch: 713, Iteration: 1/2, Loss: 1.3928640621090125\n",
      "Epoch: 714, Iteration: 1/2, Loss: 1.3924241178942458\n",
      "Epoch: 715, Iteration: 1/2, Loss: 1.3923761363311293\n",
      "Epoch: 716, Iteration: 1/2, Loss: 1.392050649928459\n",
      "Epoch: 717, Iteration: 1/2, Loss: 1.393254507801112\n",
      "Epoch: 718, Iteration: 1/2, Loss: 1.3923611165774563\n",
      "Epoch: 719, Iteration: 1/2, Loss: 1.391969078797875\n",
      "Epoch: 720, Iteration: 1/2, Loss: 1.3923271718819632\n",
      "Epoch: 721, Iteration: 1/2, Loss: 1.3919468063837943\n",
      "Epoch: 722, Iteration: 1/2, Loss: 1.3927038277404167\n",
      "Epoch: 723, Iteration: 1/2, Loss: 1.3927770052604034\n",
      "Epoch: 724, Iteration: 1/2, Loss: 1.3918519612579374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████▏               | 798/1000 [00:01<00:00, 505.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 725, Iteration: 1/2, Loss: 1.3919286938698752\n",
      "Epoch: 726, Iteration: 1/2, Loss: 1.3926507813354545\n",
      "Epoch: 727, Iteration: 1/2, Loss: 1.3919883112419753\n",
      "Epoch: 728, Iteration: 1/2, Loss: 1.3924892041645827\n",
      "Epoch: 729, Iteration: 1/2, Loss: 1.3923877111827772\n",
      "Epoch: 730, Iteration: 1/2, Loss: 1.3920944192468454\n",
      "Epoch: 731, Iteration: 1/2, Loss: 1.3923246132201723\n",
      "Epoch: 732, Iteration: 1/2, Loss: 1.3918011572826519\n",
      "Epoch: 733, Iteration: 1/2, Loss: 1.392617911766489\n",
      "Epoch: 734, Iteration: 1/2, Loss: 1.3921157766268615\n",
      "Epoch: 735, Iteration: 1/2, Loss: 1.3925944255827838\n",
      "Epoch: 736, Iteration: 1/2, Loss: 1.3918573954800468\n",
      "Epoch: 737, Iteration: 1/2, Loss: 1.391733303128266\n",
      "Epoch: 738, Iteration: 1/2, Loss: 1.392405576251882\n",
      "Epoch: 739, Iteration: 1/2, Loss: 1.3923184008291207\n",
      "Epoch: 740, Iteration: 1/2, Loss: 1.3920352022884255\n",
      "Epoch: 741, Iteration: 1/2, Loss: 1.3920862940491463\n",
      "Epoch: 742, Iteration: 1/2, Loss: 1.3921419090352503\n",
      "Epoch: 743, Iteration: 1/2, Loss: 1.3916238721477443\n",
      "Epoch: 744, Iteration: 1/2, Loss: 1.3928964035601155\n",
      "Epoch: 745, Iteration: 1/2, Loss: 1.3919999685104334\n",
      "Epoch: 746, Iteration: 1/2, Loss: 1.3917380012620506\n",
      "Epoch: 747, Iteration: 1/2, Loss: 1.3915997746050837\n",
      "Epoch: 748, Iteration: 1/2, Loss: 1.3924704677467303\n",
      "Epoch: 749, Iteration: 1/2, Loss: 1.3919145646453839\n",
      "Epoch: 750, Iteration: 1/2, Loss: 1.3916570578308822\n",
      "Epoch: 751, Iteration: 1/2, Loss: 1.3927685223312056\n",
      "Epoch: 752, Iteration: 1/2, Loss: 1.391635748509754\n",
      "Epoch: 753, Iteration: 1/2, Loss: 1.3915373743975348\n",
      "Epoch: 754, Iteration: 1/2, Loss: 1.3920381827320414\n",
      "Epoch: 755, Iteration: 1/2, Loss: 1.3919079926917273\n",
      "Epoch: 756, Iteration: 1/2, Loss: 1.3922677738523017\n",
      "Epoch: 757, Iteration: 1/2, Loss: 1.391885660972841\n",
      "Epoch: 758, Iteration: 1/2, Loss: 1.3918730865374358\n",
      "Epoch: 759, Iteration: 1/2, Loss: 1.3915960052852987\n",
      "Epoch: 760, Iteration: 1/2, Loss: 1.3922780158851986\n",
      "Epoch: 761, Iteration: 1/2, Loss: 1.3918427137974327\n",
      "Epoch: 762, Iteration: 1/2, Loss: 1.3918865725843423\n",
      "Epoch: 763, Iteration: 1/2, Loss: 1.3914985306060914\n",
      "Epoch: 764, Iteration: 1/2, Loss: 1.3922481468244015\n",
      "Epoch: 765, Iteration: 1/2, Loss: 1.3918001116435914\n",
      "Epoch: 766, Iteration: 1/2, Loss: 1.3915635448897443\n",
      "Epoch: 767, Iteration: 1/2, Loss: 1.3921597021777217\n",
      "Epoch: 768, Iteration: 1/2, Loss: 1.3917659404183595\n",
      "Epoch: 769, Iteration: 1/2, Loss: 1.3917017411052393\n",
      "Epoch: 770, Iteration: 1/2, Loss: 1.3921711273256476\n",
      "Epoch: 771, Iteration: 1/2, Loss: 1.3918687662081477\n",
      "Epoch: 772, Iteration: 1/2, Loss: 1.3913428364662475\n",
      "Epoch: 773, Iteration: 1/2, Loss: 1.391877348585119\n",
      "Epoch: 774, Iteration: 1/2, Loss: 1.3916661213414834\n",
      "Epoch: 775, Iteration: 1/2, Loss: 1.39173406063837\n",
      "Epoch: 776, Iteration: 1/2, Loss: 1.3920396288728067\n",
      "Epoch: 777, Iteration: 1/2, Loss: 1.3913975987454439\n",
      "Epoch: 778, Iteration: 1/2, Loss: 1.3917359692386069\n",
      "Epoch: 779, Iteration: 1/2, Loss: 1.3915594498064112\n",
      "Epoch: 780, Iteration: 1/2, Loss: 1.3917391330464972\n",
      "Epoch: 781, Iteration: 1/2, Loss: 1.391381097216625\n",
      "Epoch: 782, Iteration: 1/2, Loss: 1.3923104119254555\n",
      "Epoch: 783, Iteration: 1/2, Loss: 1.3912413966092076\n",
      "Epoch: 784, Iteration: 1/2, Loss: 1.3913534226767852\n",
      "Epoch: 785, Iteration: 1/2, Loss: 1.3920073534791346\n",
      "Epoch: 786, Iteration: 1/2, Loss: 1.3919466714739217\n",
      "Epoch: 787, Iteration: 1/2, Loss: 1.3915773630313826\n",
      "Epoch: 788, Iteration: 1/2, Loss: 1.391693861122234\n",
      "Epoch: 789, Iteration: 1/2, Loss: 1.3912653430216928\n",
      "Epoch: 790, Iteration: 1/2, Loss: 1.39185450814299\n",
      "Epoch: 791, Iteration: 1/2, Loss: 1.3916149913933684\n",
      "Epoch: 792, Iteration: 1/2, Loss: 1.3912172925200368\n",
      "Epoch: 793, Iteration: 1/2, Loss: 1.3914983696560714\n",
      "Epoch: 794, Iteration: 1/2, Loss: 1.3915458137223957\n",
      "Epoch: 795, Iteration: 1/2, Loss: 1.3919350766601397\n",
      "Epoch: 796, Iteration: 1/2, Loss: 1.3912022383315208\n",
      "Epoch: 797, Iteration: 1/2, Loss: 1.3915710012105027\n",
      "Epoch: 798, Iteration: 1/2, Loss: 1.3910535597382383\n",
      "Epoch: 799, Iteration: 1/2, Loss: 1.3922165703265947\n",
      "Epoch: 800, Iteration: 1/2, Loss: 1.3907703837320178\n",
      "Epoch: 801, Iteration: 1/2, Loss: 1.3918881210113216\n",
      "Epoch: 802, Iteration: 1/2, Loss: 1.391435151596018\n",
      "Epoch: 803, Iteration: 1/2, Loss: 1.3911416417608016\n",
      "Epoch: 804, Iteration: 1/2, Loss: 1.3921208429129557\n",
      "Epoch: 805, Iteration: 1/2, Loss: 1.3910895952053095\n",
      "Epoch: 806, Iteration: 1/2, Loss: 1.3917825467379417\n",
      "Epoch: 807, Iteration: 1/2, Loss: 1.3913343143333767\n",
      "Epoch: 808, Iteration: 1/2, Loss: 1.391098423371989\n",
      "Epoch: 809, Iteration: 1/2, Loss: 1.3918057512175372\n",
      "Epoch: 810, Iteration: 1/2, Loss: 1.391039386166554\n",
      "Epoch: 811, Iteration: 1/2, Loss: 1.3916535755982835\n",
      "Epoch: 812, Iteration: 1/2, Loss: 1.391150084734634\n",
      "Epoch: 813, Iteration: 1/2, Loss: 1.3910240141887313\n",
      "Epoch: 814, Iteration: 1/2, Loss: 1.391960808101668\n",
      "Epoch: 815, Iteration: 1/2, Loss: 1.391052343205525\n",
      "Epoch: 816, Iteration: 1/2, Loss: 1.3913485278435218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████▊       | 908/1000 [00:01<00:00, 510.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 817, Iteration: 1/2, Loss: 1.3912783292931783\n",
      "Epoch: 818, Iteration: 1/2, Loss: 1.3914512946225417\n",
      "Epoch: 819, Iteration: 1/2, Loss: 1.39087950496477\n",
      "Epoch: 820, Iteration: 1/2, Loss: 1.3916591179839934\n",
      "Epoch: 821, Iteration: 1/2, Loss: 1.39132394519314\n",
      "Epoch: 822, Iteration: 1/2, Loss: 1.3912173075776555\n",
      "Epoch: 823, Iteration: 1/2, Loss: 1.3913105464761535\n",
      "Epoch: 824, Iteration: 1/2, Loss: 1.3913095237743704\n",
      "Epoch: 825, Iteration: 1/2, Loss: 1.391234608930474\n",
      "Epoch: 826, Iteration: 1/2, Loss: 1.390989638742028\n",
      "Epoch: 827, Iteration: 1/2, Loss: 1.3914620411107208\n",
      "Epoch: 828, Iteration: 1/2, Loss: 1.3910198700192917\n",
      "Epoch: 829, Iteration: 1/2, Loss: 1.3911552526810884\n",
      "Epoch: 830, Iteration: 1/2, Loss: 1.3915075367647294\n",
      "Epoch: 831, Iteration: 1/2, Loss: 1.3912104163773744\n",
      "Epoch: 832, Iteration: 1/2, Loss: 1.391236806636743\n",
      "Epoch: 833, Iteration: 1/2, Loss: 1.3912007935688129\n",
      "Epoch: 834, Iteration: 1/2, Loss: 1.3911585227328445\n",
      "Epoch: 835, Iteration: 1/2, Loss: 1.391461390931824\n",
      "Epoch: 836, Iteration: 1/2, Loss: 1.3908303502868495\n",
      "Epoch: 837, Iteration: 1/2, Loss: 1.3912320173563582\n",
      "Epoch: 838, Iteration: 1/2, Loss: 1.391132626089893\n",
      "Epoch: 839, Iteration: 1/2, Loss: 1.3914255504704471\n",
      "Epoch: 840, Iteration: 1/2, Loss: 1.3909245492825564\n",
      "Epoch: 841, Iteration: 1/2, Loss: 1.391080674466031\n",
      "Epoch: 842, Iteration: 1/2, Loss: 1.3911643047675117\n",
      "Epoch: 843, Iteration: 1/2, Loss: 1.3910937664459566\n",
      "Epoch: 844, Iteration: 1/2, Loss: 1.3910299159479056\n",
      "Epoch: 845, Iteration: 1/2, Loss: 1.391461067938145\n",
      "Epoch: 846, Iteration: 1/2, Loss: 1.3907350129902556\n",
      "Epoch: 847, Iteration: 1/2, Loss: 1.3910671794334402\n",
      "Epoch: 848, Iteration: 1/2, Loss: 1.391062902678432\n",
      "Epoch: 849, Iteration: 1/2, Loss: 1.3910257089853395\n",
      "Epoch: 850, Iteration: 1/2, Loss: 1.3911059327393427\n",
      "Epoch: 851, Iteration: 1/2, Loss: 1.3914020672820782\n",
      "Epoch: 852, Iteration: 1/2, Loss: 1.3904597755790908\n",
      "Epoch: 853, Iteration: 1/2, Loss: 1.391357178704078\n",
      "Epoch: 854, Iteration: 1/2, Loss: 1.390933786690838\n",
      "Epoch: 855, Iteration: 1/2, Loss: 1.390995434629784\n",
      "Epoch: 856, Iteration: 1/2, Loss: 1.3909958522201822\n",
      "Epoch: 857, Iteration: 1/2, Loss: 1.390955359272599\n",
      "Epoch: 858, Iteration: 1/2, Loss: 1.3911128229150407\n",
      "Epoch: 859, Iteration: 1/2, Loss: 1.3909022548463499\n",
      "Epoch: 860, Iteration: 1/2, Loss: 1.3910023621878222\n",
      "Epoch: 861, Iteration: 1/2, Loss: 1.390976599174963\n",
      "Epoch: 862, Iteration: 1/2, Loss: 1.3910015198988976\n",
      "Epoch: 863, Iteration: 1/2, Loss: 1.3909153291525582\n",
      "Epoch: 864, Iteration: 1/2, Loss: 1.3908920958468922\n",
      "Epoch: 865, Iteration: 1/2, Loss: 1.3909719464602377\n",
      "Epoch: 866, Iteration: 1/2, Loss: 1.390695272822625\n",
      "Epoch: 867, Iteration: 1/2, Loss: 1.3914728939813292\n",
      "Epoch: 868, Iteration: 1/2, Loss: 1.39060389191833\n",
      "Epoch: 869, Iteration: 1/2, Loss: 1.3909120407114808\n",
      "Epoch: 870, Iteration: 1/2, Loss: 1.3905814589868308\n",
      "Epoch: 871, Iteration: 1/2, Loss: 1.3911918459299688\n",
      "Epoch: 872, Iteration: 1/2, Loss: 1.390856308320629\n",
      "Epoch: 873, Iteration: 1/2, Loss: 1.3909086954256737\n",
      "Epoch: 874, Iteration: 1/2, Loss: 1.3905536944222994\n",
      "Epoch: 875, Iteration: 1/2, Loss: 1.3911419809620336\n",
      "Epoch: 876, Iteration: 1/2, Loss: 1.3911238712043874\n",
      "Epoch: 877, Iteration: 1/2, Loss: 1.3906084908778218\n",
      "Epoch: 878, Iteration: 1/2, Loss: 1.3908736455078061\n",
      "Epoch: 879, Iteration: 1/2, Loss: 1.3910584850353498\n",
      "Epoch: 880, Iteration: 1/2, Loss: 1.390537072562037\n",
      "Epoch: 881, Iteration: 1/2, Loss: 1.3907980587451303\n",
      "Epoch: 882, Iteration: 1/2, Loss: 1.3906187685840037\n",
      "Epoch: 883, Iteration: 1/2, Loss: 1.3913465880521496\n",
      "Epoch: 884, Iteration: 1/2, Loss: 1.3905178069264919\n",
      "Epoch: 885, Iteration: 1/2, Loss: 1.3907206382016817\n",
      "Epoch: 886, Iteration: 1/2, Loss: 1.3905812207123613\n",
      "Epoch: 887, Iteration: 1/2, Loss: 1.3909299761585538\n",
      "Epoch: 888, Iteration: 1/2, Loss: 1.3908849190120072\n",
      "Epoch: 889, Iteration: 1/2, Loss: 1.39064021200282\n",
      "Epoch: 890, Iteration: 1/2, Loss: 1.3905286129738066\n",
      "Epoch: 891, Iteration: 1/2, Loss: 1.391067769440367\n",
      "Epoch: 892, Iteration: 1/2, Loss: 1.3910102408950231\n",
      "Epoch: 893, Iteration: 1/2, Loss: 1.3904262741952174\n",
      "Epoch: 894, Iteration: 1/2, Loss: 1.3907238545047729\n",
      "Epoch: 895, Iteration: 1/2, Loss: 1.3907983706817535\n",
      "Epoch: 896, Iteration: 1/2, Loss: 1.3904070892579143\n",
      "Epoch: 897, Iteration: 1/2, Loss: 1.3910051501794403\n",
      "Epoch: 898, Iteration: 1/2, Loss: 1.3906218715878778\n",
      "Epoch: 899, Iteration: 1/2, Loss: 1.39061372193366\n",
      "Epoch: 900, Iteration: 1/2, Loss: 1.3907801821449284\n",
      "Epoch: 901, Iteration: 1/2, Loss: 1.3906514036044486\n",
      "Epoch: 902, Iteration: 1/2, Loss: 1.3906434040667834\n",
      "Epoch: 903, Iteration: 1/2, Loss: 1.3907089150660423\n",
      "Epoch: 904, Iteration: 1/2, Loss: 1.3906542222036213\n",
      "Epoch: 905, Iteration: 1/2, Loss: 1.3906241648158906\n",
      "Epoch: 906, Iteration: 1/2, Loss: 1.3906468398207834\n",
      "Epoch: 907, Iteration: 1/2, Loss: 1.3903801443431387\n",
      "Epoch: 908, Iteration: 1/2, Loss: 1.3905783128423166\n",
      "Epoch: 909, Iteration: 1/2, Loss: 1.3911640145558053\n",
      "Epoch: 910, Iteration: 1/2, Loss: 1.3903669774613012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 486.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 911, Iteration: 1/2, Loss: 1.3908535630257166\n",
      "Epoch: 912, Iteration: 1/2, Loss: 1.3903856343839316\n",
      "Epoch: 913, Iteration: 1/2, Loss: 1.3908572896502545\n",
      "Epoch: 914, Iteration: 1/2, Loss: 1.3900065975439637\n",
      "Epoch: 915, Iteration: 1/2, Loss: 1.3908906794610731\n",
      "Epoch: 916, Iteration: 1/2, Loss: 1.3905738940524\n",
      "Epoch: 917, Iteration: 1/2, Loss: 1.3905445098587694\n",
      "Epoch: 918, Iteration: 1/2, Loss: 1.390561047165179\n",
      "Epoch: 919, Iteration: 1/2, Loss: 1.390772308696663\n",
      "Epoch: 920, Iteration: 1/2, Loss: 1.3903528580526048\n",
      "Epoch: 921, Iteration: 1/2, Loss: 1.390735804064867\n",
      "Epoch: 922, Iteration: 1/2, Loss: 1.3900769999607023\n",
      "Epoch: 923, Iteration: 1/2, Loss: 1.3905524114291001\n",
      "Epoch: 924, Iteration: 1/2, Loss: 1.3906673090774855\n",
      "Epoch: 925, Iteration: 1/2, Loss: 1.3903713341264856\n",
      "Epoch: 926, Iteration: 1/2, Loss: 1.3904867544220054\n",
      "Epoch: 927, Iteration: 1/2, Loss: 1.3907125376214293\n",
      "Epoch: 928, Iteration: 1/2, Loss: 1.3904963225232092\n",
      "Epoch: 929, Iteration: 1/2, Loss: 1.3907333137396294\n",
      "Epoch: 930, Iteration: 1/2, Loss: 1.3900555903646727\n",
      "Epoch: 931, Iteration: 1/2, Loss: 1.3907205495413606\n",
      "Epoch: 932, Iteration: 1/2, Loss: 1.390163909536249\n",
      "Epoch: 933, Iteration: 1/2, Loss: 1.3905303113648186\n",
      "Epoch: 934, Iteration: 1/2, Loss: 1.3908842112048245\n",
      "Epoch: 935, Iteration: 1/2, Loss: 1.3901694671250502\n",
      "Epoch: 936, Iteration: 1/2, Loss: 1.390799450014541\n",
      "Epoch: 937, Iteration: 1/2, Loss: 1.3901633147059442\n",
      "Epoch: 938, Iteration: 1/2, Loss: 1.3907036491710263\n",
      "Epoch: 939, Iteration: 1/2, Loss: 1.3901461591190305\n",
      "Epoch: 940, Iteration: 1/2, Loss: 1.39019490895754\n",
      "Epoch: 941, Iteration: 1/2, Loss: 1.390626012464933\n",
      "Epoch: 942, Iteration: 1/2, Loss: 1.390704754204724\n",
      "Epoch: 943, Iteration: 1/2, Loss: 1.390338513057729\n",
      "Epoch: 944, Iteration: 1/2, Loss: 1.3901822058410689\n",
      "Epoch: 945, Iteration: 1/2, Loss: 1.3901241948926495\n",
      "Epoch: 946, Iteration: 1/2, Loss: 1.3906997528339144\n",
      "Epoch: 947, Iteration: 1/2, Loss: 1.3906081810648523\n",
      "Epoch: 948, Iteration: 1/2, Loss: 1.3901067065634165\n",
      "Epoch: 949, Iteration: 1/2, Loss: 1.3903612580592881\n",
      "Epoch: 950, Iteration: 1/2, Loss: 1.3900847292266496\n",
      "Epoch: 951, Iteration: 1/2, Loss: 1.3904245988939845\n",
      "Epoch: 952, Iteration: 1/2, Loss: 1.3907826879394722\n",
      "Epoch: 953, Iteration: 1/2, Loss: 1.390321250683264\n",
      "Epoch: 954, Iteration: 1/2, Loss: 1.3902005250696388\n",
      "Epoch: 955, Iteration: 1/2, Loss: 1.3901931436557904\n",
      "Epoch: 956, Iteration: 1/2, Loss: 1.3901206635621042\n",
      "Epoch: 957, Iteration: 1/2, Loss: 1.3905871623128354\n",
      "Epoch: 958, Iteration: 1/2, Loss: 1.390340195604788\n",
      "Epoch: 959, Iteration: 1/2, Loss: 1.3905107691945542\n",
      "Epoch: 960, Iteration: 1/2, Loss: 1.3900089319383293\n",
      "Epoch: 961, Iteration: 1/2, Loss: 1.390432485228147\n",
      "Epoch: 962, Iteration: 1/2, Loss: 1.3904924224956425\n",
      "Epoch: 963, Iteration: 1/2, Loss: 1.390013854576082\n",
      "Epoch: 964, Iteration: 1/2, Loss: 1.3903203667593687\n",
      "Epoch: 965, Iteration: 1/2, Loss: 1.3902517644026058\n",
      "Epoch: 966, Iteration: 1/2, Loss: 1.3901781027210802\n",
      "Epoch: 967, Iteration: 1/2, Loss: 1.3903033500470698\n",
      "Epoch: 968, Iteration: 1/2, Loss: 1.3902864461042457\n",
      "Epoch: 969, Iteration: 1/2, Loss: 1.390044940503754\n",
      "Epoch: 970, Iteration: 1/2, Loss: 1.3903768931437446\n",
      "Epoch: 971, Iteration: 1/2, Loss: 1.3902386914211804\n",
      "Epoch: 972, Iteration: 1/2, Loss: 1.390258638851087\n",
      "Epoch: 973, Iteration: 1/2, Loss: 1.3902944378008693\n",
      "Epoch: 974, Iteration: 1/2, Loss: 1.3904146680244458\n",
      "Epoch: 975, Iteration: 1/2, Loss: 1.3900229610941501\n",
      "Epoch: 976, Iteration: 1/2, Loss: 1.3899672186637417\n",
      "Epoch: 977, Iteration: 1/2, Loss: 1.3904644801800325\n",
      "Epoch: 978, Iteration: 1/2, Loss: 1.390374849262508\n",
      "Epoch: 979, Iteration: 1/2, Loss: 1.3899818870597942\n",
      "Epoch: 980, Iteration: 1/2, Loss: 1.3902502780790646\n",
      "Epoch: 981, Iteration: 1/2, Loss: 1.3898583697293372\n",
      "Epoch: 982, Iteration: 1/2, Loss: 1.3904551262413984\n",
      "Epoch: 983, Iteration: 1/2, Loss: 1.3901100943015439\n",
      "Epoch: 984, Iteration: 1/2, Loss: 1.390207478591122\n",
      "Epoch: 985, Iteration: 1/2, Loss: 1.3901366700272693\n",
      "Epoch: 986, Iteration: 1/2, Loss: 1.3901553206663526\n",
      "Epoch: 987, Iteration: 1/2, Loss: 1.3902156647689876\n",
      "Epoch: 988, Iteration: 1/2, Loss: 1.3900618539963796\n",
      "Epoch: 989, Iteration: 1/2, Loss: 1.3901802905851062\n",
      "Epoch: 990, Iteration: 1/2, Loss: 1.390327218443586\n",
      "Epoch: 991, Iteration: 1/2, Loss: 1.3901937994926703\n",
      "Epoch: 992, Iteration: 1/2, Loss: 1.3899306504971776\n",
      "Epoch: 993, Iteration: 1/2, Loss: 1.3903050933717953\n",
      "Epoch: 994, Iteration: 1/2, Loss: 1.389606688419637\n",
      "Epoch: 995, Iteration: 1/2, Loss: 1.390107551906207\n",
      "Epoch: 996, Iteration: 1/2, Loss: 1.390288759612765\n",
      "Epoch: 997, Iteration: 1/2, Loss: 1.390371812843588\n",
      "Epoch: 998, Iteration: 1/2, Loss: 1.3896908523687046\n",
      "Epoch: 999, Iteration: 1/2, Loss: 1.3902531370189006\n",
      "Epoch: 1000, Iteration: 1/2, Loss: 1.3900391286696325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "\n",
    "# configurations\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "# define model\n",
    "skip_gram = SkipGram(vocab_size=len(word2idx), hidden_size=hidden_size, window_size=window_size)\n",
    "sgd_optimizer = SGD()\n",
    "trainer = Trainer(skip_gram, sgd_optimizer)\n",
    "\n",
    "# start training\n",
    "trainer.fit(contexts, targets, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural [ 0.16589083 -2.236172   -1.5839291   0.6988937  -1.3915342 ]\n",
      "studying [ 1.1796643   1.7634431   1.7227309   0.58583415 -0.5138855 ]\n",
      ". [-0.00439008  0.00923975 -0.00680103 -0.02705207 -0.01214297]\n",
      "language [-0.09813242  1.4367162   1.5380844  -0.90099937  2.039908  ]\n",
      "now [-1.6882036  -0.38495916 -0.43559682 -1.5338247   1.6015465 ]\n",
      "processing [ 0.0869865  -1.959536    0.82959706  1.8407598   0.41483608]\n",
      "i [-0.00700054 -0.02036355 -0.00430416  0.01152475 -0.00137651]\n",
      "am [ 0.28105742  0.6135118  -2.1624184  -0.72468585 -1.5795735 ]\n"
     ]
    }
   ],
   "source": [
    "# check skip-gram results\n",
    "word_vecs = skip_gram.word_vecs\n",
    "for word_id, word in idx2word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
